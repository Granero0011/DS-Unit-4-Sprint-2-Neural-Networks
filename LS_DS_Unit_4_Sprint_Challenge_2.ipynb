{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "nteract": {
      "version": "0.14.3"
    },
    "colab": {
      "name": "LS_DS_Unit_4_Sprint_Challenge_2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Granero0011/DS-Unit-4-Sprint-2-Neural-Networks/blob/master/LS_DS_Unit_4_Sprint_Challenge_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7P3qy8utdLGp",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2*\n",
        "\n",
        "# Sprint Challenge - Neural Network Foundations\n",
        "\n",
        "Table of Problems\n",
        "\n",
        "1. [Defining Neural Networks](#Q1)\n",
        "2. [Perceptron on XOR Gates](#Q2)\n",
        "3. [Multilayer Perceptron](#Q3)\n",
        "4. [Keras MMP](#Q4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWnXlVULdLGr",
        "colab_type": "text"
      },
      "source": [
        "<a id=\"Q1\"></a>\n",
        "## 1. Define the following terms:\n",
        "\n",
        "- **Neuron:**\n",
        "- **Input Layer:**\n",
        "- **Hidden Layer:**\n",
        "- **Output Layer:**\n",
        "- **Activation:**\n",
        "- **Backpropagation:**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKCmxGg8eUKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Answering the questions\n",
        "''' Neuron: A neuron is a basic unit of a neural network\n",
        "    Input layer: An input layer is the first layer, which receives the the source data\n",
        "    Hidden layer: layer in between input layers and output layers, where artificial neurons take in a set of weighted inputs and produce an output through an activation function \n",
        "    Output layer: layer that produces the output \n",
        "    Activation: defines the output by applying a function to the input\n",
        "    Backpropagation: Mechanism by which neural networks learn'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2J3RMZlLdLGs",
        "colab_type": "text"
      },
      "source": [
        "## 2. Perceptron on XOR Gates <a id=\"Q3=2\"></a>\n",
        "\n",
        "Create a perceptron class that can model the behavior of an AND gate. You can use the following table as your training data:\n",
        "\n",
        "|x1\t|x2|x3|\ty|\n",
        "|---|---|---|---|\n",
        "1|\t1|\t1|\t1|\n",
        "1|\t0|\t1|\t0|\n",
        "0|\t1|\t1|\t0|\n",
        "0|\t0|\t1|\t0|"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V30qDpBWoKyb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Let's load the libraries\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "inputHidden": false,
        "outputHidden": false,
        "id": "jlpRilgkdLGt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Perceptron class \n",
        "class Perceptron(object):\n",
        "    \"\"\"Implements a perceptron network\"\"\"\n",
        "    def __init__(self, input_size, lr=1, epochs=100):\n",
        "        self.W = np.zeros(input_size+1)\n",
        "        # add one for bias\n",
        "        self.epochs = epochs\n",
        "        self.lr = lr\n",
        "    \n",
        "    def activation_fn(self, x):\n",
        "        #return (x >= 0).astype(np.float32)\n",
        "        return 1 if x >= 0 else 0\n",
        " \n",
        "    def predict(self, x):\n",
        "        z = self.W.T.dot(x)\n",
        "        a = self.activation_fn(z)\n",
        "        return a\n",
        " \n",
        "    def fit(self, X, d):\n",
        "        for _ in range(self.epochs):\n",
        "            for i in range(d.shape[0]):\n",
        "                x = np.insert(X[i], 0, 1)\n",
        "                y = self.predict(x)\n",
        "                e = d[i] - y\n",
        "                self.W = self.W + self.lr * e * x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mh_RGz5dnjok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Let's create the example\n",
        "X = np.array([[1,1,1],[1,0,1],[0,1,1],[0,0,1]])\n",
        "d=np.array([1, 0, 0, 0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFI9yx2ooYgO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "19b0cc60-f78b-4e1f-e3ee-2eae76f7b695"
      },
      "source": [
        "#Let's check the weights\n",
        "perceptron = Perceptron(input_size=3)\n",
        "perceptron.fit(X, d)\n",
        "print(perceptron.W)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-2.  1.  3. -2.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcmqeG-hdLGx",
        "colab_type": "text"
      },
      "source": [
        "## 3. Multilayer Perceptron <a id=\"Q3\"></a>\n",
        "\n",
        "Implement a Neural Network Multilayer Perceptron class that uses backpropagation to update the network's weights.\n",
        "Your network must have one hidden layer.\n",
        "You do not have to update weights via gradient descent. You can use something like the derivative of the sigmoid function to update weights.\n",
        "Train your model on the Heart Disease dataset from UCI:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "inputHidden": false,
        "outputHidden": false,
        "id": "7_udrhmYdLGy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWg3kicTdLG1",
        "colab_type": "text"
      },
      "source": [
        "## 4. Keras MMP <a id=\"Q4\"></a>\n",
        "\n",
        "Implement a Multilayer Perceptron architecture of your choosing using the Keras library. Train your model and report its baseline accuracy. Then hyperparameter tune at least two parameters and report your model's accuracy.\n",
        "Use the Heart Disease Dataset (binary classification)\n",
        "Use an appropriate loss function for a binary classification task\n",
        "Use an appropriate activation function on the final layer of your network.\n",
        "Train your model using verbose output for ease of grading.\n",
        "Use GridSearchCV to hyperparameter tune your model. (for at least two hyperparameters)\n",
        "When hyperparameter tuning, show you work by adding code cells for each new experiment.\n",
        "Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy.\n",
        "You must hyperparameter tune at least 5 parameters in order to get a 3 on this section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "inputHidden": false,
        "outputHidden": false,
        "id": "hs6hborndLG2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}